{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##This is the diver for the generic bootstrap particle filter\n",
    "\n",
    "from pylab import *\n",
    "from scipy.integrate import odeint\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load L63_vectorized.py\n",
    "def L63_vectorized(state,t):\n",
    "    \n",
    "    \"\"\"This is the vectorized derivative for the Lorenz 63 model\"\"\"\n",
    "    # Define the system parameters\n",
    "    sigma = 10.0\n",
    "    rho   = 28.0\n",
    "    beta  = 8.0/3.0\n",
    "    \n",
    "    # Reshape the state vector to apply the derivative  \n",
    "    particles = len(state)/3\n",
    "    state = reshape(state,[particles,3])\n",
    "    \n",
    "    # unpack the state variables\n",
    "    X = state[:,0]\n",
    "    Y = state[:,1]\n",
    "    Z = state[:,2]\n",
    "\n",
    "    dx = sigma*(Y-X)\n",
    "    dy = X*(rho - Z) - Y\n",
    "    dz = X*Y - beta*Z\n",
    "    \n",
    "\n",
    "    \n",
    "    deriv = array([dx,dy,dz]).transpose()\n",
    "    deriv = reshape(deriv,particles*3)\n",
    "    \n",
    "    return deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load particle_filter.py\n",
    "def  bootstrap(model,initial,ens_size,weights,interval,nanl,tanl,obs,Q):\n",
    "\n",
    "    \"\"\"This is a general bootstrap particle filter function\n",
    "    \n",
    "    The fields to supply are the derivative function `model', the initial cloud\n",
    "    'initial', the model dimension and cloud size,\n",
    "    the particle weights at initialization `weights', the interval \n",
    "    to integrate the cloud '`interval', the observation with which to \n",
    "    update the cloud at the end analysis time, and the inverse of the \n",
    "    observational error covaraince `Q'.\n",
    "    \n",
    "    We assume that the model is vectorized to accept a cloud of initial\n",
    "    conditions of the shape [model_dimension, cloud_size].\"\"\"\n",
    "    ipdb.set_trace()\n",
    "    \n",
    "    # store the analysis times indices in the full integration interval\n",
    "    a_time = array(range(0,len(interval)+1,tanl))-1\n",
    "    a_time[0] = 0\n",
    "    \n",
    "    # storage matrix for the trajectories\n",
    "    traj = zeros([len(interval),intial.size])\n",
    "    \n",
    "    for i in range(nanl):\n",
    "        # integrate the initial cloud to the analysis time\n",
    "        traj[a_time[i]:a_time[i+1],:] = odeint(model,initial,\n",
    "                                               interval[a_time[i]:a_time[i+1]])\n",
    "        \n",
    "        # reset intial condition\n",
    "        intial = traj[a_time[i+1]]\n",
    "        \n",
    "        #compute the likelyhood function\n",
    "        innov = reshape(initial,[ens_size,model_dim])\n",
    "        \"\"\"need to check if the dimensions here are all right\"\"\"\n",
    "        innov = obs - innov.transpose()\n",
    "        temp  = sum(Q.dot(innov)*innov,axis=0)\n",
    "        likelyhood = exp(-0.5*temp)**(1.0/3.0)\n",
    "    \n",
    "        weights = weights*likelyhood\n",
    "    \n",
    "    return [traj,weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## System Parameters\n",
    "\n",
    "# Define the number of particles in the ensemble\n",
    "root = 2\n",
    "particle_number = root**3\n",
    "\n",
    "# Spin time\n",
    "spin_end = 10\n",
    "\n",
    "# Time step\n",
    "dt = .01\n",
    "\n",
    "# Spin interval\n",
    "spin = linspace(0,spin_end,spin_end/dt)\n",
    "\n",
    "# Obs Err variance (% of climate variance) \n",
    "obs_var = 0.01\n",
    "\n",
    "# Analysis interval\n",
    "tanl = 50\n",
    "\n",
    "# Number of Analyses\n",
    "nanl = 100\n",
    "\n",
    "# Experiment length\n",
    "exp_len = tanl*nanl\n",
    "exp_int = linspace(0,exp_len*dt,exp_len)\n",
    "\n",
    "# state dimension\n",
    "state_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Spin up the ensemble of initial conditions for the filter and `truth'\n",
    "\n",
    "# Assign cubes of initial conditions for the ensemble spin up, run the spin,calculate spin mean, \n",
    "# and variance to set initial conditions for the runs\n",
    "ens_base = randint(-100,100)\n",
    "\n",
    "# Define cube of initial conditions for the spin up \n",
    "cube = zeros([particle_number,state_dim])\n",
    "\n",
    "for i in range(root):\n",
    "    for j in range(root):\n",
    "        for k in range(root):            \n",
    "            cube[(root**2)*i + root*j + k, :] =(array([k*exp(-1),j*exp(-1),i*exp(-1)])+ens_base)\n",
    "                                                      \n",
    "\n",
    "# Spin up the initial cloud\n",
    "spin_cloud = reshape(cube,3*particle_number)\n",
    "spin_cloud = odeint(L63_vectorized,spin_cloud,spin)\n",
    "spin_cloud = reshape(spin_cloud,[len(spin),particle_number,state_dim])\n",
    "spun_cloud = spin_cloud[-1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Calcualte the environmental statistics\n",
    "\n",
    "#Determine the mean for the spin cloud at each time step\n",
    "spin_mean = mean(spun_cloud,axis=0)\n",
    "\n",
    "#Calculate variance of the mean along spin up\n",
    "cl_var = 2*var(spun_cloud,axis=0)\n",
    "\n",
    "#Observational Error covariance stored    \n",
    "R = cl_var*eye(state_dim)*obs_var\n",
    "Q = inv(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Create the `perfect' model experiment\n",
    "\n",
    "# Generate random ensemble member to be initializaiton for `truth'\n",
    "P = randint(0,particle_number)\n",
    "truth = spun_cloud[P,:]\n",
    "\n",
    "# `Truth' state is eliminated from the particle cloud\n",
    "PF_cloud = delete(spun_cloud,P,0)\n",
    "\n",
    "# Propagate a `true' trajectory to generate the observations\n",
    "truth = odeint(L63_vectorized,truth,exp_int)\n",
    "truth = reshape(truth,[exp_len,3])\n",
    "\n",
    "#Create observations with error, note the tanl-1 so that accounts for index beginning at 0\n",
    "obs = truth[tanl-1:exp_len:tanl,:] + (randn(nanl,3)*sqrt(obs_var*cl_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Run bootstrap filter on the sequence of observations with the intialized cloud\n",
    "\n",
    "# Set the weights and initial conditions\n",
    "ens_size = len(PF_cloud[:,0])\n",
    "weights = 1.0/(ens_size)\n",
    "weights = weights*ones(ens_size)\n",
    "\n",
    "PF_cloud = reshape(PF_cloud,PF_cloud.size)\n",
    "\n",
    "%debug\n",
    "\n",
    "[traj,weights] = bootstrap(L63_vectorized,PF_cloud,ens_size,weights,exp_int,nanl,tanl,obs,Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
