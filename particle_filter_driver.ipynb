{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##This is the diver for the generic bootstrap particle filter\n",
    "\n",
    "from pylab import *\n",
    "from scipy.integrate import odeint\n",
    "from L63_V import L63\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load particle_filter.py\n",
    "def  bootstrap(model,state_dim,prior,ens_size,weights,interval,nanl,tanl,obs,Q):\n",
    "\n",
    "    \"\"\"This is a general bootstrap particle filter function\n",
    "    \n",
    "    The fields to supply are the derivative function `model', the initial cloud\n",
    "    'initial', the model dimension and cloud size,\n",
    "    the particle weights at initialization `weights', the interval \n",
    "    to integrate the cloud '`interval', the observation with which to \n",
    "    update the cloud at the end analysis time, and the inverse of the \n",
    "    observational error covaraince `Q'.\n",
    "    \n",
    "    We assume that the model is vectorized to accept a cloud of initial\n",
    "    conditions of the shape [model_dimension, cloud_size].\"\"\"\n",
    "    \n",
    "    # store the analysis times indices in the full integration interval\n",
    "    a_time = array(range(0,len(interval),tanl))\n",
    "\n",
    "    # storage dictionary for the trajectories and weights\n",
    "    p_series = {}\n",
    "    A = 'A_'\n",
    "    \n",
    "    # divergence safety check\n",
    "    divergence = False\n",
    "    \n",
    "    # loop through the analysis times starting at time zero\n",
    "    for i in range(nanl):\n",
    "        \n",
    "        # recompute the weights and load into the dict as a tuple\n",
    "        [analysis,weights,ens_size] = no_resample_update(weights,obs[i,:],Q,prior,ens_size,state_dim)\n",
    "        \n",
    "        # check for filter divergence\n",
    "        if ens_size < 10:\n",
    "            divergence = True\n",
    "            A_i = A + str(i)\n",
    "            p_series[A_i] = [prior,analysis,weights]\n",
    "            break\n",
    "        \n",
    "        # integrate the initial cloud to the next analysis time;\n",
    "        # note integration interval starts at time 0, and slice notation goes to the last index - 1\n",
    "        traj = odeint(model,analysis,interval[a_time[i]:a_time[i+1]+1])\n",
    "        \n",
    "        #create storage for next iteration\n",
    "        A_i = A + str(i)\n",
    "        p_series[A_i] = [prior, analysis, weights, traj]\n",
    "        \n",
    "        #initialize the next forecast\n",
    "        prior = traj[-1,:]\n",
    "        \n",
    "    # final analysis time weight update\n",
    "    ipdb.set_trace()\n",
    "    if not divergence:\n",
    "        [analysis,weights,ens_size] = no_resample_update(weights,obs[i+1,:],Q,prior,ens_size,state_dim)\n",
    "        A_i = A + str(i+1)\n",
    "        p_series[A_i] = [prior, analysis, weights]\n",
    "    \n",
    "    return p_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_obs(model,truth,H,exp_int,nanl,tanl,obs_var):\n",
    "    \n",
    "    \"\"\"This function generates a sequence of observations for analysis\n",
    "    \n",
    "    Given the model, the initialization of the truth, observational operator H,\n",
    "    the interval of the experiment integration, the number of analyses, the \n",
    "    time interval between analyses, and the vector of observational variances (assuming\n",
    "    covariances are zero), this function returns a sequence of observations given by perturbations\n",
    "    of the the true trajectory.\"\"\"\n",
    "    \n",
    "    # Define the model and obs dimensions\n",
    "    [obs_dim,state_dim] = shape(H)\n",
    "    \n",
    "    # Propagate a `true' trajectory to generate the observations\n",
    "    truth = odeint(L63,truth,exp_int)\n",
    "    truth = reshape(truth,[exp_len+1,3])\n",
    "\n",
    "    # Create observations with error, with first observation at time zero, and ranging to\n",
    "    # time exp_len, at intervals of tanl\n",
    "    obs = H.dot(truth[::tanl,:]) + (randn(nanl+1,state_dim)*sqrt(obs_var))\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## System Parameters\n",
    "\n",
    "# Define the number of particles in the ensemble\n",
    "root = 8\n",
    "particle_number = root**3\n",
    "\n",
    "# Spin time\n",
    "spin_end = 1000\n",
    "\n",
    "# Time step\n",
    "dt = .01\n",
    "\n",
    "# Spin interval\n",
    "spin = linspace(0,spin_end,spin_end/dt)\n",
    "\n",
    "# Obs Err variance (% of climate variance) \n",
    "obs_var = 0.01\n",
    "\n",
    "# Analysis performed after tanl steps\n",
    "tanl = 10\n",
    "\n",
    "# Number of Analyses (after the analysis at time zero)\n",
    "nanl = 1000\n",
    "\n",
    "# Experiment length defined\n",
    "exp_len = tanl*nanl\n",
    "\n",
    "# Interval of integration including time zero\n",
    "exp_int = linspace(0,exp_len*dt,exp_len+1)\n",
    "\n",
    "# state dimension\n",
    "state_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def attractor_spin(particle_number,root,model,state_dim,obs_var):\n",
    "    \n",
    "    \"\"\"Spin up the ensemble of initial conditions for the filter and `truth'\n",
    "    \n",
    "    Assign cubes of initial conditions for the ensemble spin up, run the spin,calculate \n",
    "    spin mean, and variance to set initial conditions for the experiment.  The number\n",
    "    of particles must be a cubic, and the cube root of the number of particles is supplied\n",
    "    as `root'.\"\"\" \n",
    "\n",
    "    # Generate basepoint for the cube of initial conditions\n",
    "    ens_base = randint(-100,100)\n",
    "\n",
    "    # Define cube of initial conditions for the spin up \n",
    "    cube = zeros([particle_number,state_dim])\n",
    "\n",
    "    for i in range(root):\n",
    "        for j in range(root):\n",
    "            for k in range(root):            \n",
    "                cube[(root**2)*i + root*j + k, :] =(array([k*exp(-1),j*exp(-1),i*exp(-1)])+ens_base)\n",
    "                                                      \n",
    "\n",
    "    # Spin up the initial cloud\n",
    "    spin_cloud = reshape(cube,3*particle_number)\n",
    "    spin_cloud = odeint(L63,spin_cloud,spin)\n",
    "    spin_cloud = reshape(spin_cloud,[len(spin),particle_number,state_dim])\n",
    "    spun_cloud = spin_cloud[-1,:,:]\n",
    "\n",
    "    ## Calcualte the environmental statistics\n",
    "\n",
    "    #Determine the mean for the spin cloud at each time step\n",
    "    spin_mean = mean(spun_cloud,axis=0)\n",
    "\n",
    "    #Calculate variance of the mean along spin up\n",
    "    cl_var = 2*var(spun_cloud,axis=0)\n",
    "    obs_var = obs_var*cl_var\n",
    "\n",
    "    #Observational Error covariance stored    \n",
    "    R = eye(state_dim)*obs_var\n",
    "    Q = inv(R)\n",
    "\n",
    "    ## Create the truth for `perfect' model experiment\n",
    "\n",
    "    # Generate random ensemble member to be initializaiton for `truth'\n",
    "    P = randint(0,particle_number)\n",
    "    truth = spun_cloud[P,:]\n",
    "\n",
    "    # `Truth' state is eliminated from the particle cloud\n",
    "    PF_cloud = delete(spun_cloud,P,0)\n",
    "    \n",
    "    return [truth,PF_cloud,Q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Run bootstrap filter on the sequence of observations with the intialized cloud\n",
    "\n",
    "# Set the weights and initial conditions\n",
    "ens_size = len(PF_cloud[:,0])\n",
    "weights = 1.0/(ens_size)\n",
    "weights = weights*ones(ens_size)\n",
    "%debug\n",
    "PF_cloud = reshape(PF_cloud,PF_cloud.size)\n",
    "\n",
    "pdf_series = bootstrap(L63,state_dim,PF_cloud,ens_size,weights,exp_int,nanl,tanl,obs,Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attractor_spin(particle_number,root,L63,state_dim,obs_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
